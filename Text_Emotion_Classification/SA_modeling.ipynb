{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17655</th>\n",
       "      <td>3</td>\n",
       "      <td>quot never alon love realli know quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>0</td>\n",
       "      <td>wait gt gg load annoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>2</td>\n",
       "      <td>feel import enough live worthi enough struggl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13326</th>\n",
       "      <td>5</td>\n",
       "      <td>god want sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24733</th>\n",
       "      <td>6</td>\n",
       "      <td>drive gt 90mph daili basi cld film fast amp fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18918</th>\n",
       "      <td>3</td>\n",
       "      <td>joe photograph famili rehears alway fun first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18132</th>\n",
       "      <td>3</td>\n",
       "      <td>coffe gym start day right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21216</th>\n",
       "      <td>4</td>\n",
       "      <td>watch short stack tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11048</th>\n",
       "      <td>2</td>\n",
       "      <td>inde love team incred attent ball chees live g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>3</td>\n",
       "      <td>got approxim 3 hour sleep last nighti love life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "17655      3              quot never alon love realli know quot\n",
       "2335       0                              wait gt gg load annoy\n",
       "9286       2  feel import enough live worthi enough struggl ...\n",
       "13326      5                                     god want sleep\n",
       "24733      6  drive gt 90mph daili basi cld film fast amp fu...\n",
       "...      ...                                                ...\n",
       "18918      3  joe photograph famili rehears alway fun first ...\n",
       "18132      3                          coffe gym start day right\n",
       "21216      4                               watch short stack tv\n",
       "11048      2  inde love team incred attent ball chees live g...\n",
       "19647      3    got approxim 3 hour sleep last nighti love life\n",
       "\n",
       "[11200 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SA_model_data')\n",
    "data = data[['label','text']]\n",
    "data.text=data.text.astype(str)\n",
    "\n",
    "#data, final_data = train_test_split(data, test_size = 0.6, random_state = 42, stratify=data['label'])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 33, 128)           1280000   \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 33, 128)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 98)                88984     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 693       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,369,677\n",
      "Trainable params: 1,369,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 98\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7504, 33) (7504, 7)\n",
      "(3696, 33) (3696, 7)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['label']).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 133s 3s/step - loss: 1.9269 - accuracy: 0.1929 - val_loss: 1.8997 - val_accuracy: 0.2633\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 132s 3s/step - loss: 1.7709 - accuracy: 0.3463 - val_loss: 1.7291 - val_accuracy: 0.3597\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 131s 3s/step - loss: 1.3932 - accuracy: 0.5217 - val_loss: 1.5101 - val_accuracy: 0.4267\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 128s 3s/step - loss: 0.9862 - accuracy: 0.6674 - val_loss: 1.3989 - val_accuracy: 0.4867\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 128s 3s/step - loss: 0.7044 - accuracy: 0.7761 - val_loss: 1.4385 - val_accuracy: 0.4880\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 125s 3s/step - loss: 0.5092 - accuracy: 0.8435 - val_loss: 1.4539 - val_accuracy: 0.4920\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 127s 3s/step - loss: 0.3895 - accuracy: 0.8810 - val_loss: 1.7244 - val_accuracy: 0.4734\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 140s 3s/step - loss: 0.3092 - accuracy: 0.9086 - val_loss: 1.7197 - val_accuracy: 0.4893\n",
      "Epoch 9/10\n",
      "23/42 [===============>..............] - ETA: 1:03 - loss: 0.2368 - accuracy: 0.9266"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 3s - loss: 1.4535 - accuracy: 0.5030 - 3s/epoch - 136ms/step\n",
      "score: 1.45\n",
      "acc: 0.50\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 'anger': 0,\n",
    "            'fear': 1,\n",
    "            'happiness': 2,\n",
    "            'love': 3,\n",
    "            'rq': 4,\n",
    "            'sadness': 5,\n",
    "            'worry': 6}\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "\n",
    "#filename = 'sa_model_i1.sav'\n",
    "#model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Function to decode prediction to a class\n",
    "def get_text_prediction(text):\n",
    "    text = str(text)\n",
    "    # vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "    vector = tokenizer.texts_to_sequences(text)\n",
    "    #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "    vector = pad_sequences(vector, maxlen=34, dtype='int32', value=0)\n",
    "    sentiment = model.predict(vector, batch_size=1, verbose = 2)[0]\n",
    "    sentiment = np.argmax(sentiment)\n",
    "    sentiment = [k for k, v in classes.items() if v == sentiment]\n",
    "    print('Input text: ', text)\n",
    "    print('Predicted class: ', sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 1s - 1s/epoch - 118ms/step\n",
      "Input text:  love you!\n",
      "Predicted class:  ['rq']\n"
     ]
    }
   ],
   "source": [
    "#get_text_prediction('we focus only on positive aspects and integration.')\n",
    "get_text_prediction('love you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://171d4718-c6d0-4003-bf09-51ca115ba69b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://171d4718-c6d0-4003-bf09-51ca115ba69b/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model to disk\n",
    "#filename = 'sa_model_i1.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
