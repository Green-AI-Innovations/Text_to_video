{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6c1abe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in c:\\users\\andre\\anaconda3\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: click in c:\\users\\andre\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andre\\anaconda3\\lib\\site-packages (from opendatasets) (4.65.0)\n",
      "Requirement already satisfied: kaggle in c:\\users\\andre\\anaconda3\\lib\\site-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.9)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.27.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "73d6d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\andre\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\andre\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: anyascii in c:\\users\\andre\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3d072002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f627b3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4071f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "import copy\n",
    "import contractions\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3556074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\isear-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# ISEAR dataset\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/faisalsanto007/isear-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f96b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "isear_dataset = pd.read_csv(\"isear-dataset/eng_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "10e589d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ID column\n",
    "\n",
    "isear_dataset = isear_dataset.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9b655ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "isear_dataset.rename(columns={'sentiment': 'emotion', 'content': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ac144d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\emotion-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# Emotion-dataset\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/parulpandey/emotion-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "25b52397",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dataset_test = pd.read_csv(\"emotion-dataset/test.csv\")\n",
    "emotion_dataset_training = pd.read_csv(\"emotion-dataset/training.csv\")\n",
    "emotion_dataset_validation = pd.read_csv(\"emotion-dataset/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8dcb5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\emotions-dataset-for-nlp\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# Emotions dataset for NLP\n",
    "\n",
    "od.download(\"https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "116387f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_dataset_for_nlp_test = pd.read_csv(\"emotions-dataset-for-nlp/test.txt\", header=None)\n",
    "emotions_dataset_for_nlp_training = pd.read_csv(\"emotions-dataset-for-nlp/train.txt\", header=None)\n",
    "emotions_dataset_for_nlp_validation = pd.read_csv(\"emotions-dataset-for-nlp/val.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6b3b3e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a column in 2, at the \";\" symbol\n",
    "\n",
    "emotions_dataset_for_nlp_test = emotions_dataset_for_nlp_test[0].str.split(\";\", n = 1, expand = True)\n",
    "emotions_dataset_for_nlp_training = emotions_dataset_for_nlp_training[0].str.split(\";\", n = 1, expand = True)\n",
    "emotions_dataset_for_nlp_validation = emotions_dataset_for_nlp_validation[0].str.split(\";\", n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "565db1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "emotions_dataset_for_nlp_test.rename(columns={0: 'text', 1: 'emotion'}, inplace=True)\n",
    "emotions_dataset_for_nlp_training.rename(columns={0: 'text', 1: 'emotion'}, inplace=True)\n",
    "emotions_dataset_for_nlp_validation.rename(columns={0: 'text', 1: 'emotion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "232bc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\emotion-detection-from-text\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ad3aa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion detection from text dataset\n",
    "\n",
    "emotion_detection_from_text = pd.read_csv(\"emotion-detection-from-text/tweet_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "104774a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_detection_from_text = emotion_detection_from_text.drop('tweet_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1bcb78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "emotion_detection_from_text.rename(columns={'sentiment': 'emotion', 'content': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3ea09073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "\n",
    "emotion_dataset_test.rename(columns={'label': 'emotion'}, inplace=True)\n",
    "emotion_dataset_training.rename(columns={'label': 'emotion'}, inplace=True)\n",
    "emotion_dataset_validation.rename(columns={'label': 'emotion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1cccfdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for emotion_dataset, renaming sadness to (0), joy to (1), love to (2), anger to (3), fear to (4).\n",
    "\n",
    "dct = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"}\n",
    "emotion_dataset_test[\"emotion\"].replace(dct, inplace=True)\n",
    "emotion_dataset_training[\"emotion\"].replace(dct, inplace=True)\n",
    "emotion_dataset_validation[\"emotion\"].replace(dct, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "37b1eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sadness', 'joy', 'fear', 'anger', 'love', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(emotion_dataset_test['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ff0b4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['emotion', 'text'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "Index(['emotion', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(isear_dataset.columns)\n",
    "print(emotion_dataset_test.columns)\n",
    "print(emotion_dataset_training.columns)\n",
    "print(emotion_dataset_validation.columns)\n",
    "print(emotions_dataset_for_nlp_test.columns)\n",
    "print(emotions_dataset_for_nlp_training.columns)\n",
    "print(emotions_dataset_for_nlp_validation.columns)\n",
    "print(emotion_detection_from_text.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "51532a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87102"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(isear_dataset)+len(emotion_dataset_test)+len(emotion_dataset_training)+len(emotion_dataset_validation)+len(emotions_dataset_for_nlp_test)+len(emotions_dataset_for_nlp_training)+len(emotions_dataset_for_nlp_validation)+len(emotion_detection_from_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fb26fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all dataframes along rows\n",
    "\n",
    "data = pd.concat([isear_dataset, emotion_dataset_test, emotion_dataset_training, emotion_dataset_validation, emotions_dataset_for_nlp_test, emotions_dataset_for_nlp_training, emotions_dataset_for_nlp_validation, emotion_detection_from_text], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7d0e830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87102, 2), Index(['emotion', 'text'], dtype='object'))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5f059cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion                                                anger\n",
      "text       @moocowward @mrsajhargreaves @Melly77 @GaryBar...\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "140d0cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'fear', 'joy', 'sadness', 'love', 'surprise', 'empty',\n",
       "       'enthusiasm', 'neutral', 'worry', 'fun', 'hate', 'happiness',\n",
       "       'boredom', 'relief'], dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7770b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct1 = {\"joy\": \"happiness\"}\n",
    "data[\"emotion\"].replace(dct1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d8c7e5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'fear', 'happiness', 'sadness', 'love', 'surprise',\n",
       "       'empty', 'enthusiasm', 'neutral', 'worry', 'fun', 'hate',\n",
       "       'boredom', 'relief'], dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(data[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "596b47ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         emotion                                               text\n",
       "0          anger  At the point today where if someone says somet...\n",
       "1          anger  @CorningFootball  IT'S GAME DAY!!!!      T MIN...\n",
       "2          anger  This game has pissed me off more than any othe...\n",
       "3          anger  @spamvicious I've just found out it's Candice ...\n",
       "4          anger  @moocowward @mrsajhargreaves @Melly77 @GaryBar...\n",
       "...          ...                                                ...\n",
       "39995    neutral                                   @JohnLloydTaylor\n",
       "39996       love                     Happy Mothers Day  All my love\n",
       "39997       love  Happy Mother's Day to all the mommies out ther...\n",
       "39998  happiness  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
       "39999       love  @mopedronin bullet train from tokyo    the gf ...\n",
       "\n",
       "[87102 rows x 2 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "120dd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5787a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing abbreviations with full word versions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8c3f76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_content(text):\n",
    "\n",
    "    text = expand_contractions(text)\n",
    "    \n",
    "    # remove twitter handles\n",
    "    clean_text = re.sub(r'@\\w+\\s?', '', text)\n",
    "    \n",
    "    # remove twitter hashtags\n",
    "    clean_text = re.sub(r'#\\w+\\s?', '', clean_text)\n",
    "    \n",
    "    # convert to lowercase\n",
    "    clean_text = clean_text.lower()\n",
    "    \n",
    "    # remove links http:// or https://\n",
    "    clean_text = re.sub(r'https?:\\/\\/\\S+', '', clean_text)\n",
    "    \n",
    "    # remove links href://\n",
    "    clean_text = re.sub(r'\\bhref\\w*\\b', ' ', clean_text)\n",
    "    \n",
    "    # remove links beginning with www. and ending with .com\n",
    "    clean_text = re.sub(r'www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)', '', clean_text)\n",
    "    \n",
    "    # remove html reference characters\n",
    "    clean_text = re.sub(r'&[a-z]+;', '', clean_text)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8a6f23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x :  clean_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "911347cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: [item for item in x.split() if item not in stop_words]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ec16b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text): # emojis converted to chars\n",
    "    x = re.sub(r'[^A-Za-z0-9 ]+', '', str(text))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f6838123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = data['text'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5c8f8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    txt = copy.deepcopy(text)\n",
    "    for punctuation in string.punctuation:     \n",
    "        txt = txt.replace(punctuation, '')\n",
    "    return txt\n",
    "\n",
    "data[\"text\"] = data['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3a1dc0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness     20347\n",
       "sadness       18292\n",
       "neutral        8638\n",
       "worry          8459\n",
       "anger          7229\n",
       "love           7124\n",
       "fear           6998\n",
       "surprise       3625\n",
       "fun            1776\n",
       "relief         1526\n",
       "hate           1323\n",
       "empty           827\n",
       "enthusiasm      759\n",
       "boredom         179\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ad6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
