{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFTtfeOFo7dD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDuigwdrpUo0"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/churn_gpt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAIL_YmV7gOC"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XMiAVzQr7csS"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0EiOVjLPs0mL"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20334</th>\n",
              "      <td>rq</td>\n",
              "      <td>fun time friend beer pic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5420</th>\n",
              "      <td>fear</td>\n",
              "      <td>simpli said sorri got car got hous feel restless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>anger</td>\n",
              "      <td>ok eye doctor guy take forev sit cold room mys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24762</th>\n",
              "      <td>worry</td>\n",
              "      <td>listen ryan adam sick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8251</th>\n",
              "      <td>happiness</td>\n",
              "      <td>relax thank hope get put foot tomorrow enjoy day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14994</th>\n",
              "      <td>sadness</td>\n",
              "      <td>know everi babi differ feel like alreadi exhau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20866</th>\n",
              "      <td>rq</td>\n",
              "      <td>watch star trek yet thought watch last night w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13049</th>\n",
              "      <td>sadness</td>\n",
              "      <td>sick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14939</th>\n",
              "      <td>sadness</td>\n",
              "      <td>feel broke fix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25780</th>\n",
              "      <td>worry</td>\n",
              "      <td>worri friend</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5600 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         emotion                                               text\n",
              "20334         rq                           fun time friend beer pic\n",
              "5420        fear   simpli said sorri got car got hous feel restless\n",
              "1992       anger  ok eye doctor guy take forev sit cold room mys...\n",
              "24762      worry                              listen ryan adam sick\n",
              "8251   happiness   relax thank hope get put foot tomorrow enjoy day\n",
              "...          ...                                                ...\n",
              "14994    sadness  know everi babi differ feel like alreadi exhau...\n",
              "20866         rq  watch star trek yet thought watch last night w...\n",
              "13049    sadness                                               sick\n",
              "14939    sadness                                     feel broke fix\n",
              "25780      worry                                       worri friend\n",
              "\n",
              "[5600 rows x 2 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('SA_model_data', low_memory=False, index_col=0)\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "data, final_data = train_test_split(data, test_size = 0.8, random_state = 42, stratify=data['emotion'])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "V4vKx2x5s1Pc"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "#data = data[data['type'].isin(['churn', 'non_churn'])]  # Filter out 'cool-off' instances\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yDXWCwU7FF_5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "worry        651\n",
              "anger        648\n",
              "rq           641\n",
              "sadness      641\n",
              "happiness    640\n",
              "love         632\n",
              "fear         627\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.emotion.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zYecri0es1Ry"
      },
      "outputs": [],
      "source": [
        "# Create a custom dataset class\n",
        "class ProspectDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.label_mapping = {  'anger': 0,\n",
        "                                'fear': 1,\n",
        "                                'happiness': 2,\n",
        "                                'love': 3,\n",
        "                                'rq': 4,\n",
        "                                'sadness': 5,\n",
        "                                'worry': 6}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        text = row[\"text\"]\n",
        "        label = row[\"emotion\"]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "            \"label\": torch.tensor(self.label_mapping[label], dtype=torch.long),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MFB9iAEqs1UT"
      },
      "outputs": [],
      "source": [
        "# Set up hyperparameters, tokenizer, and datasets\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_LEN = 100\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_CLASSES = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrL6xBi9FzpB"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vbFsfGt_s1Ws"
      },
      "outputs": [],
      "source": [
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "train_dataset = ProspectDataset(train_data, tokenizer, MAX_LEN)\n",
        "test_dataset = ProspectDataset(test_data, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-dKs89F5s1ZD"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PH0neb7Fs1bz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/Users/andrew/miniforge3/envs/tensorflow/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained model and fine-tune\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=NUM_CLASSES)#.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nrqUxsPFs1eL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training:\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input nan is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch\u001b[39m\u001b[39m\"\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     input_ids \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m#.to(device)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m#.to(device)\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[0;32mIn[29], line 23\u001b[0m, in \u001b[0;36mProspectDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m text \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m label \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39memotion\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[1;32m     24\u001b[0m     text,\n\u001b[1;32m     25\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     26\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_len,\n\u001b[1;32m     27\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     28\u001b[0m     truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     31\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     35\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msqueeze(),\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msqueeze(),\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_mapping[label], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong),\n\u001b[1;32m     38\u001b[0m }\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2709\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2699\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2700\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2701\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2702\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2706\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2707\u001b[0m )\n\u001b[0;32m-> 2709\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   2710\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2711\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2712\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2713\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2714\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2715\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2716\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2717\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2718\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2719\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2720\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2721\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2722\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2723\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2724\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2725\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2726\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2727\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2728\u001b[0m )\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/transformers/tokenization_utils.py:649\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    650\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[1;32m    653\u001b[0m     first_ids,\n\u001b[1;32m    654\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    669\u001b[0m )\n",
            "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.10/site-packages/transformers/tokenization_utils.py:635\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m is not valid. Should be a string or a list/tuple of strings when\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m `is_split_into_words=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    636\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    638\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Input nan is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "print(\"Training:\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    train_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=\"Batch\", leave=False):\n",
        "        input_ids = batch[\"input_ids\"]#.to(device)\n",
        "        attention_mask = batch[\"attention_mask\"]#.to(device)\n",
        "        labels = batch[\"label\"]#.to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Average training loss: {avg_train_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eowplzOgs1gj"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "model.eval()\n",
        "print(\"\\nTesting:\")\n",
        "predictions, true_labels = [], []\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Batch\", leave=False):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        test_loss += loss.item()\n",
        "        logits = outputs.logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to(\"cpu\").numpy()\n",
        "\n",
        "        predictions.extend(np.argmax(logits, axis=1))\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "print(f\"Average testing loss: {avg_test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj5dHziB8wN7"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5weJ1DvgMl6"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je8mBj4df4PJ"
      },
      "outputs": [],
      "source": [
        "# Import required functions and libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsOhK-53gAMj"
      },
      "outputs": [],
      "source": [
        "# Print classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predictions, target_names=[\"churn\", \"non-churn\"]))\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate false positive and false negative scores\n",
        "false_positive = conf_matrix[0][1]\n",
        "false_negative = conf_matrix[1][0]\n",
        "print(f\"False Positive Score: {false_positive} (predict )\")\n",
        "print(f\"False Negative Score: {false_negative}\")\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"churn\", \"non-churn\"], yticklabels=[\"churn\", \"non-churn\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.ylabel(\"True label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQJG3hKn8yM5"
      },
      "source": [
        "# Save the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsj7VlZB83N5"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"fine_tuned_multilingual_bert\")\n",
        "# tokenizer.save_pretrained(\"fine_tuned_multilingual_bert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkTdrwJX814U"
      },
      "source": [
        "# Load the fine-tuned model for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV-tb9Ems1lr"
      },
      "outputs": [],
      "source": [
        "# loaded_model = BertForSequenceClassification.from_pretrained(\"fine_tuned_multilingual_bert\").to(device)\n",
        "# loaded_tokenizer = BertTokenizer.from_pretrained(\"fine_tuned_multilingual_bert\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
